{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PATH ridership information is published as a PDF which makes it so unbelievably inconvenient to work with for analytic purposes.\n",
    "PATH ridership data: https://www.panynj.gov/path/statistics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabula requires java\n",
    "import tabula\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "pdf_path = \"../data/path_ridership_data/2019-PATH-hourly-Ridership-Report.pdf\"\n",
    "file_name_output = '2019-PATH-hourly-Ridership-Report.csv'\n",
    "\n",
    "#constants\n",
    "months = [1,2,3,4,5,6,7,8,9,10,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "tables = tabula.read_pdf(\n",
    "    pdf_path,\n",
    "    multiple_tables=True,\n",
    "    encoding='ISO-8859-1',\n",
    "    pages='all')\n",
    "\n",
    "print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumnNames(first_row, second_row):\n",
    "    length = min(len(first_row), len(second_row))\n",
    "    columnNames = []\n",
    "    for index in np.arange(length):\n",
    "        words1 = first_row[index]\n",
    "        words2 = second_row[index]\n",
    "        if pd.isnull(words1):\n",
    "            words1 = \"\"\n",
    "        if pd.isnull(words2):\n",
    "            words2 = \"\"\n",
    "        if words1 == \"\" and words2 == \"\":\n",
    "            columnNames.append(\"BLANK\")\n",
    "        elif words1 == \"\" or words2 == \"\":\n",
    "            columnNames.append(words1 + words2)\n",
    "        else:\n",
    "            columnNames.append(words1 + \" \" + words2)\n",
    "    return columnNames\n",
    "\n",
    "station_data = {}\n",
    "\n",
    "for table in tables:\n",
    "    station_name = table.iloc[0][1]\n",
    "    data = []\n",
    "    if station_name in station_data:\n",
    "        data = station_data[station_name]\n",
    "    \n",
    "    names = getColumnNames(table.iloc[1], table.iloc[2])\n",
    "    while True:\n",
    "        if \"BLANK\" in names:\n",
    "            blank_index = names.index(\"BLANK\")\n",
    "            table = table.drop([table.columns[blank_index]] ,  axis='columns')\n",
    "            names.pop(blank_index)\n",
    "        else:\n",
    "            break\n",
    "    table.columns = names\n",
    "  \n",
    "    table = table.iloc[3:len(table)-1,:]\n",
    "    table = table.reset_index(drop=True)\n",
    "    table = table.fillna(0)\n",
    "    data.append(table)\n",
    "    station_data[station_name] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to add month, year, and station name to the \n",
    "# dataframes so we can later combine them into one csv file\n",
    "# Note: if you want to rerun this cell, rerun the cell above first\n",
    "\n",
    "# idk why Tabula splits System-wide into two tables    \n",
    "station_data.pop('Avg Weekday', None)\n",
    "station_data.pop('System?wide', None)\n",
    "\n",
    "# for station_name in station_data:\n",
    "#     #spot check, all stations should have 13 stations\n",
    "#     print(station_name, len(station_data[station_name]))\n",
    "\n",
    "for station_name in station_data:\n",
    "    data = station_data[station_name]\n",
    "    # first value are the year-end stats\n",
    "    data.pop(0)\n",
    "    for index in np.arange(len(data)):\n",
    "        data[index]['month'] = months[index]\n",
    "        data[index]['station'] = station_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_station = []\n",
    "for station_name in station_data:\n",
    "    data = station_data[station_name]\n",
    "    data_per_station.append(pd.concat(data))\n",
    "        \n",
    "        \n",
    "master_df = pd.concat(data_per_station)\n",
    "len(master_df)\n",
    "\n",
    "master_df.to_csv(file_name_output, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
